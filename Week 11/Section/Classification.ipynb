{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details style='font-size:16px'><summary style='font-size:22px'>Learning Objectives:</summary>\n",
    "\n",
    "- Understanding Different Classification methods.\n",
    "- Apply Classification algorithms on various data sets to solve real world problems.\n",
    "- Understnad evaluation methods in Classification\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".imgHolder {\n",
       "    position: relative;\n",
       "}\n",
       ".imgHolder span {\n",
       "    position: absolute;\n",
       "    right: 10px;\n",
       "    top: 10px;\n",
       "    color: Black;\n",
       "    font-weight: bold;\n",
       "    font-size: 18px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Style of images within its comment under it\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".imgHolder {\n",
    "    position: relative;\n",
    "}\n",
    ".imgHolder span {\n",
    "    position: absolute;\n",
    "    right: 10px;\n",
    "    top: 10px;\n",
    "    color: Black;\n",
    "    font-weight: bold;\n",
    "    font-size: 18px;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Introduction to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the classification?\n",
    "\n",
    "- A *Supervised learning approach.*\n",
    "\n",
    "- Categorizing some unkown items into a discrete set of categories or \"classes\".\n",
    "\n",
    "- The target attribute is a **categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  How does classification work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Simple-class Classification:***\n",
    "\n",
    "> **Classification** determines the class label for an unlabeled test case.\n",
    "<img src=\"Modules_images/classification_idea.png\" style='float:right;'>\n",
    "- Example for simple- class classification:\n",
    "    + Suppose a brand is concerned about the potential for loans not to be rapaid?\n",
    "\n",
    "    + If previous loan default data can be used to predict which customers are likely to have problems repaying loans. These bad risk customers can either have their loan application declined or offered alternative products.\n",
    "\n",
    "    + The goal of a loan defualt predictor is to use existing loan default data which has info. about the customers such as income, age, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Multi-class Classification***:\n",
    "<img src=\"Modules_images/classification_multi.png\" style='float:right;'>\n",
    "- Example, \n",
    "\n",
    "    + Imagine having collected data about set of patients.\n",
    "\n",
    "    + All of them suffered the same illness.\n",
    "\n",
    "    + During their course of treatment, each patient responded to one of the Three medications. User can use this labeled dataset with a classification algorithm to build a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification use cases\n",
    "\n",
    "- Which category customer belongs to?\n",
    "\n",
    "- Whether a customer switches to another provider/brand?\n",
    "\n",
    "- Whether a customer responds to a particular advertising campaign?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification algorithms in Machine Learning\n",
    "\n",
    "- Decision Tree (ID3, C4.5, C5.5)\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "- K-Nearest Neighbor\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- Neural Networks\n",
    "\n",
    "- Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that a telecommunication provider has segmented his customer base by service usage patterns, categorizing the customers into 4 groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a simple but powerful algorithm used for classification tasks, particularly in machine learning. It's based on Bayes' theorem, which is a probability theory that helps us update our beliefs based on new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(B|A) = \\frac{\\overbrace{p(A|B)}^{\\text{likelihood}} \\overbrace{p(B)}^{\\text{prior}}}{\\underbrace{p(A)}_{\\text{evidence}}}\n",
    "$$\n",
    "\n",
    "- $p(B|A)$ is the posterior probability of event $B$ given the occurrence of event $A$.\n",
    "- $p(A|B)$ is the likelihood, representing the probability of event $A$ given the occurrence of event $B$.\n",
    "- $p(B)$ is the prior probability of event $B$, expressing our initial belief about its occurrence before considering the evidence.\n",
    "- $p(A)$ is the evidence, also known as the marginal likelihood or the probability of event $A$, integrating over all possible occurrences of event $B$.\n",
    "\n",
    "The Naive Bayes assumption comes into play when we express the likelihood as a product of individual feature probabilities, assuming independence among features given the class label.\n",
    "\n",
    "Here's a simplified example of how you might implement this in mathematical terms:\n",
    "\n",
    "Let $ \\mathcal X = (x_1, x_2, \\ldots, x_n) $ be the features, and $ \\mathcal Y $ be the class label.\n",
    "\n",
    "\n",
    "Starting with the likelihood expression:\n",
    "\n",
    "$$p(\\mathcal{Y}|\\mathcal{X}) = \\frac{p(\\mathcal{Y}) \\prod_{i=1}^{n} p(x_i | y)}{p(\\mathcal{X})}$$\n",
    "\n",
    "Due to the conditional independence assumption in Naive Bayes, we often assume that $ p(\\mathcal{X}) $ is independent of $ p(\\mathcal{Y}) $, the class label. Therefore, we can simplify the expression by canceling out $ p(\\mathcal{X}) $:\n",
    "\n",
    "$$p(\\mathcal{Y}|\\mathcal{X}) = \\frac{p(\\mathcal{Y}) \\prod_{i=1}^{n} p(x_i | y)}{p(\\mathcal{X})} = \\frac{p(\\mathcal{Y}) \\prod_{i=1}^{n} p(x_i | y)}{\\text{{constant}}}$$\n",
    "\n",
    "The constant here is $ p(\\mathcal{X}) $, which can be disregarded when calculating posterior probabilities, as it does not depend on the class label $ y $. Hence, the likelihood in the context of Naive Bayes is often simplified to:\n",
    "\n",
    "$$p(y_j|\\mathcal{X}) = \\prod_{i=1}^{n} p(x_i | y_j)$$\n",
    "\n",
    "Now, let $ \\mathcal{X} = (x_1, x_2, \\ldots, x_n) $ be the features, and $ \\mathcal{Y} $ be the class label. To compute $p(y_j|\\mathcal{X})$, we can use the simplified likelihood expression:\n",
    "\n",
    "$$p(y_j|\\mathcal{X}) = \\prod_{i=1}^{n} p(x_i | y_j)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of Naive Bayes, \"naive\" refers to the assumption that features used to describe an observation are independent of each other. Even though this assumption may not always hold true in real-world scenarios, the simplicity of Naive Bayes makes it computationally efficient and often surprisingly effective.\n",
    "\n",
    "Let's break it down with an example. Suppose you want to classify emails as either spam or not spam (ham). Naive Bayes would analyze the occurrence of different words in both spam and ham emails. If an email contains words like \"free,\" \"discount,\" and \"limited-time offer,\" the algorithm might lean towards classifying it as spam based on the probability of these words being associated with spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking an example of a dataset of students:\n",
    "<img src=\"Modules_images/nb_studentdataset.png\" style='width:800px; height:441px'>\n",
    "\n",
    "\n",
    "And I want to compute the class of a particular phenomenon. How can we calculate it with the Naive Bayes approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Modules_images/nb_studentdataset_solution.png\" style='width:800px; height:441px'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Naive Bayes in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate some example data (you'd typically load real-world data)\n",
    "# Here, we have two features (X) and a binary target variable (y)\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5], [1, 3], [2, 4], [3, 5], [4, 6]]\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1]  # 0 represents one class, and 1 represents another\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Inroduction to  Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a decision tree?\n",
    "\n",
    "> The basic intuition behind a decision tree is to map out all possible decision paths in the form of a tree. \"*Narendra Nath Joshi*\"\n",
    "\n",
    "<img src=\"Modules_images/decision_tree_2.png\" style='float:left; width:800px; height:441px'>\n",
    "<img src=\"Modules_images/decision_teee.png\"  style='float:right; width:900px; height:441px'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Learning algorithm\n",
    "<img src=\"Modules_images/decision_tree_3.png\" style='float:right;'>\n",
    "\n",
    "> A decision tree can be constucted by considering the attribute one by one.\n",
    "\n",
    "1. Choose an attirbute from your dataset.\n",
    "\n",
    "2. Calculate **the significance** of an attribute in splitting of the data. (*We will explain how to calculate the significance of an attribute \"column\" to see if it's effective or not!*)\n",
    "\n",
    "3. Split data based on the value of the best attribute.\n",
    "\n",
    "4. Go to step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision Tree are built using recursive partitioning to classify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we talked about how can attriute effect on the data when you're branching the tree depending on especific attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Senario 1. \n",
    "<img src=\"Modules_images/attribute_1.png\" style='float:right;'>\n",
    "\n",
    "- As we can see, we've 14 cases.\n",
    "- With this attribute, we can't decide which Drug of `A` or `B` will be effective for each `Normal` and `high`. Due to **High Impurity** of the labeled class for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Senario 2. \n",
    "<img src=\"Modules_images/attribute_2.png\" style='float:right;'>\n",
    "\n",
    "- With the same 14 cases.\n",
    "\n",
    "- This time we picked `Sex` attribute of patients. Then split the data into two features `Male` and `female`.\n",
    "\n",
    "    + As we can see, if the patient is `female`, we can say that `Drug B` might be suitable for her with **high certainty**. (Due to less impurity)\n",
    "\n",
    "    + But, we don't have sufficient evidence or info. to determine if `Drug A` or `Drug B` is suitable for `male` feature.\n",
    "\n",
    "    + However, it is a better choice in comparison with `Cholesterol` attribute because the result in the nodes are **more pure**.\n",
    "\n",
    "    + From we're seeing, we can say that `Sex` attribute is more significant than `cholesterol`. In other word, its more predictive than the other attributes.\n",
    "\n",
    "    + Indeed, predictiveness is based on decrease in **impurity of nodes**. Since we're looking for the best feature to decrease the impurity of patients in leaves.\n",
    "\n",
    "    + So, **What's entropy?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "> Measure of **randomness** or **uncertainty**.\n",
    "<div class=\"imgHolder\">\n",
    "    <img src=\"Modules_images/entropy.png\" style='float:right;'>\n",
    "    <span>Entropy Evaluation</span>\n",
    "</div>\n",
    "\n",
    "<div class=\"imgHolder\">\n",
    "    <img src=\"Modules_images/entropy_1.png\" style='float:right;'>\n",
    "    <span style='right:525px;'>Entropy Before Splitting</span>\n",
    "</div>\n",
    "\n",
    "**The lower the entropy, the less uniform the distribution, the purer the node.**\n",
    "\n",
    "<span style='font-size: 18px'>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "*Entropy* = -p(A)log(p(A)) - p(B)log(p(B))\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Evaluation\n",
    "\n",
    "<div class=\"imgHolder\">\n",
    "    <img src=\"Modules_images/entropy_cal1.png\" style='float:right;' width='650px'>\n",
    "    <span>Entropy Cholesterol Evaluation</span>\n",
    "</div>\n",
    "\n",
    "<div class=\"imgHolder\">\n",
    "    <img src=\"Modules_images/entropy_cal2.png\" style='float:left;'>\n",
    "    <span style='right:825px'>Entropy Sex Evaluation</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we've different types of **Entropy** between two Features. So, how can we decided which one is the best attribute? We can do that using something called **Information Gain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's information gain?\n",
    "\n",
    "<img src=\"Modules_images/information_gain.png\" style='float:right;'>\n",
    "\n",
    "> **Information gain** is information that can increase the level of cetainty after splitting.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "*Information Gain* = (Entropy before splitting) - (weighted entropy after splitting)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "As you can see, **The less your *Weighted Entropy* after splitting, the more *Information Gain***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which attribute is the best?\n",
    "<center>\n",
    "<img src=\"Modules_images/information_gain_1.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after we select the `Sex` attribute, What's the next attribute after branching by the `Sex` attribute?\n",
    "<img src=\"Modules_images/build_next.png\" style='float:right;'>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "    + As we mentioned before, `Decision Tree` is a recursive partitioning which separating the data after each partition until it reaches out the full tree with the right attributes on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (D) Introduction to Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color: cyan; font-weight:bold'>What's Logistic Regression?</h3>\n",
    "\n",
    "> *Is a Classification algorithm for **Categorical variables**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have here, is based on a telecommunication dataset that we would like to analyze in order to understand which customer might leave the next month.\n",
    "\n",
    "- This's *historical customer data*  where each row represents one customer.\n",
    "\n",
    "- Based on this *historical record*  and use it to predict the future `churn` within the customer group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Modules_images/Logistic_reg.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color: cyan; font-weight:bold'>In which situations do we use logistic regression?<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression to build a model for predicting `customer hurn` using the given features with **one or more independent variables** to predict an outcome as such `churn` we call **dependent variable**, representing whether or not customers will stop using this service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between *Linear Regression* and *Logistic Regression***:\n",
    "\n",
    "- In **Linear Regression**, \n",
    "\n",
    "    + we might try to predict a *continuous variables* such as <u>Price of a house, blood pressure of a patient, or fuel consumption of a car.</u>\n",
    "\n",
    "\n",
    "- In **Logisitic Regression**, \n",
    "    \n",
    "    + we predict a variable which is *binary*  such as <u> Yes/no, True/false. Successful/ not successful, pregnant/nor pregnant.</u> all of which can be coded as zero or one.\n",
    "\n",
    "    + **Independent variables** should be continuous. If **categorical variables**, they should be *dummy* or *indicator coded*. Which mean you've to *transform* them to some **continuous values**.\n",
    "    \n",
    "    + Please note that logistic regression can be used for both *binary classification* and *multi-class classification*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Applications\n",
    "\n",
    "    - Predicting the probability of a person having a heart attack.\n",
    "\n",
    "    - Predicting the mortality in injured patients.\n",
    "\n",
    "    - Predicting a customer's propensity to purchase a product or halt a subscription.\n",
    "\n",
    "    - Predicting the probability of failure of a given process or product.\n",
    "\n",
    "    - Predicting the likeihood of a homeowner defualting on a mortgage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color: cyan; font-weight:bold'> When is the Logistic Regression suitable?</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Modules_images/logistic_linearly_separate.png\" style='float: right'>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- If your data is binary\n",
    "\n",
    "\n",
    "    + 0/1, YES/NO, True/False, churn/ not churn, positive/negative, and so on.\n",
    "\n",
    "    + If you want to know what the probability is of a customer buying a product.\n",
    "\n",
    "    + Logistic regression returns a probaility score between zero and one for sample of data.\n",
    "\n",
    "    + if your data is *linearly separable*. When you need linear decision boundary.\n",
    "    \n",
    "    + If  you understand the impact of a feature. (you can select the feature based on the statistical significance of the logistic. Something like correlation in linear regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model for customer churn\n",
    "\n",
    "<img src=\"Modules_images/churn_model.png\" style='float: right'>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "    + We defined the Independent Variables as X and dependent variables as Y.\n",
    "\n",
    "    + The goal of logistic regression is to build a model to predict the class of each sample.\n",
    "\n",
    "    - which in this case is a customer, as well as the probability of each sample belonging to a class.\n",
    "\n",
    "- For that let's formalize this problem;\n",
    "\n",
    "    + X --> belongs to a real number (%R) of m ( dimension or features) x n ( row records or observation).\n",
    "\n",
    "    + Y ---> the class we want to predict, which can be either 0 or 1.\n",
    "\n",
    "    + Yhat --> probability of class of customer, given X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Vs. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better understanding, we're going to display each of them, and implement their model build into the same dataset `Telecommunication` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression `income` predicting:\n",
    "<center>\n",
    "<img src=\"Modules_images/linear_predicting_1.png\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the `income`  which is a continuous value.\n",
    "\n",
    "If we select an **independent variable** such as `age` and predict the **dependent variable** `income`.\n",
    "\n",
    "We can plot it and show `age` as **independent variable** and `income` as **predicted variable**.\n",
    "\n",
    "With **linear regression**, you can *fit* a line or polynomial throuh the data.\n",
    "\n",
    "Also, we find this line through training our model or calculating it, mathematically based on the sample set.\n",
    "\n",
    "This line as an equation shown as $\\hat{y} = a + b x_1$\n",
    "\n",
    "Now we can *predict* the continuous value, `y` to predict the `income` of an unknown customer based on his/her `age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression `Churn` predicting:\n",
    "\n",
    "> **After all these mathematical equations, What's the probability that this value belongs to `class 0`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Modules_images/linear_predicting_2.png\">\n",
    "</center>\n",
    "According this the results, from the step function, <u>No matter how big the value is, as long as its greater than `0.5`, it simply equals one and vice versa.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Modules_images/linear_predicting_3.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of how small the value `y` is, <u>the output would be zero if it is less than `0.5`</u> \n",
    "\n",
    "At the end, We need a method that give us the proability of falling in the class as well. **what is the scientific solution here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `Theta transpose` we use a specific function called **sigmoid**;\n",
    "\n",
    "- **Sigmoid** is calculating the probability of of $\\theta^T$ instead of calculating the value of it, directly.\n",
    "\n",
    "<center>\n",
    "<img src=\"Modules_images/sigmoid.png\">\n",
    "</center>\n",
    "\n",
    "**So, What's Sigmoid Function?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logistic Function**\n",
    ">*It's resembling the step function and is used by the following expression in the logistic regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Modules_images/sigmoid_function.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that in sigmoid function**\n",
    "\n",
    "-> When the value of $\\theta^TX$ gets <u>very big</u>, \n",
    "- $e^{-\\theta^TX}$ in the denominator of the fraction becomes almost `0`, \n",
    "-  and the value of the **sigmoid function** get closer to 1.\n",
    "\n",
    "-> When the value of $\\theta^TX$ gets <u>very small</u>, \n",
    "- $e^{-\\theta^TX}$ in the denominator of the fraction becomes almost `1`,\n",
    "- and the value of the **sigmoid function** get closer to 0.\n",
    "\n",
    "So, it is obvious that when the outcome of the **sigmoid  function** gets closer to `1`, the p(y) equals `1` and <u>`x` goes up</u>.\n",
    "\n",
    "In contrast, when the **sigmoid function** value is closer to 0, the p(y) equals `1` given <u>`x` is very small</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of the customer churn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the output of our model when we use the sigmoid function**?\n",
    "\n",
    "    -  P(Y=1 |X)\n",
    "    - P(Y=0 |X) = 1 - P(Y=1 |x)\n",
    "\n",
    "For example;\n",
    "\n",
    "If, \n",
    "\n",
    "- P(Churn=1| income, age) = 0.8 (for instance)\n",
    "\n",
    "Then,\n",
    "\n",
    "- P(Churn=0 | income, age) = 1 - 0.8 = 0.2\n",
    "\n",
    "<center style='font-size:21px;'>\n",
    "$\\sigma(\\theta^TX)\\; \\to\\;P(Y=1 | x)$\n",
    "</center>\n",
    "\n",
    "<center style='font-size:21px;'>\n",
    "$1- \\sigma(\\theta^TX)\\; \\to\\;P(Y=0 | x)$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "### The Training Process &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\sigma(\\theta^TX)\\; \\to\\;\n",
    "P(Y=1 | x)$\n",
    "\n",
    "1. <span style='color:yellow'>Initialize $\\theta$ with random values as with most machine learning alogrithms. &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\theta$ = [-1, 2]</span>\n",
    "\n",
    "2. Calculate the model output which is $\\hat{y} = \\sigma(\\theta^TX)$ for a customer (2, 5) represents (income, age). &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\hat{y} = \\sigma([-1, 2] \\times [2, 5])  = 0.7$\n",
    "\n",
    "3. Compare the output of $\\hat{y}$ with actual output of customer, `y`, and record it as error.&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;Error = 1 - 0.7 = 0.3\n",
    "    + This's the error for only one customer out of all customers in the training set.\n",
    "\n",
    "\n",
    "4. Calculate the error for all customers. &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Cost = $J(\\theta)$\n",
    "\n",
    "    + <u>The total error is cost of your model and is calculated by the models cost function</u>. **The cost function**, by the way basically represents how to calculate the error of the model which is the difference between **the actual** and the **model predicted values**. \n",
    "\n",
    "    + the cost shows how poorly the model is estimating the customer labels, therefore the lower the cost, the better the model is at estimating the customers labels correctly.\n",
    "\n",
    "    + what we want to do is to <u>try to minimize this cost.</u>\n",
    "    \n",
    "5. Change the $\\theta$ to reduce the cost. &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\theta_{new}$\n",
    "\n",
    "6. <span style='color:yellow'>Go Back to step 2.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "There're two important question;\n",
    "\n",
    "1. How can we change the values of $\\theta$ so that *the cost* is reduced across iterations?\n",
    "\n",
    "    + There're different way to change the values of $\\theta$ but one of the most popular ways is **gradient descent**.\n",
    "<br>\n",
    "<br>\n",
    "2. When should we stop the iterations?\n",
    "\n",
    "    + There're various ways to stop iterations, but essentially you stop training by calculating **the accuracy of your model** and stop it when it's satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. General cost function\n",
    "\n",
    "$\\sigma(\\theta^TX)\\; \\to\\; P(y=1|x)$\n",
    "\n",
    "- Change the weight ($\\theta$) -> Reduce the cost\n",
    "\n",
    "- **Cost Function**:\n",
    "\n",
    "<center style='font-size:21px'>\n",
    "Derivative of the cost function, we can find how to change the parameters to reduce the cost rather the error, lets dive into it to see how it works.\n",
    "<br>\n",
    "$Cost(\\hat{y},\\; y) = \\frac{1}{2} (\\sigma(\\theta^TX)\\; -\\; y)^2$ (<strong>very complex to solve</strong>)\n",
    "    \n",
    "</center>\n",
    "<br>\n",
    "<br>\n",
    "<center style='font-size:21px'>\n",
    "$J(\\theta) = \\frac{1}{m} \\sum^m_{i-1}{Cost(\\hat{y},\\; y)}$\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the cost function of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Modules_images/cost_function.png\" style='float: right'>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- Model $\\hat{y}$\n",
    "\n",
    "\n",
    "- Actual Value y=1 or 0 (*we want to find a simple cost function for our model*)\n",
    "\n",
    "- If Y=1, and $\\hat{y}\\; \\to\\; cost=0$ (*If the predicted value is `1` or near to `1`, the cost value goes to `0` or near to `0`*).\n",
    "\n",
    "- If Y=0, and $\\hat{y}\\; \\to\\; cost=large$ (*If the predicted value is `0` or near to `0` and the actual value is `1`, the cost value goes to **HIGH***).\n",
    "\n",
    "- **Minus log function** such a cost function for us. It means if the actual value `1` and the model also predict `1`, the minus log function returns `zero cost`.\n",
    "- If **minus log function** returns <u>large value</u> so, we can use the minus log function for calculating <u>the cost of our logistic regression</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, Logistic regression cost function\n",
    "\n",
    "So, we will replace the cost function with \n",
    "\n",
    "<center>\n",
    "<img src=\"Modules_images/cost_function_main.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's recap logistic regression cost function:\n",
    "\n",
    "> *Our objective was to find a model that best estimates the actual labels.*\n",
    "\n",
    "Finding the best model is to find the best parameters' $\\theta$ for that model. So, the fittest question was;\n",
    "\n",
    "- How to find the best parameters for our model?\n",
    "\n",
    "    + Minimize the cost function. In other words, to minimize the ***J($\\theta$)***\n",
    "\n",
    "\n",
    "- How to minimize the cost function?\n",
    "\n",
    "    + Using **Gradient Descent**\n",
    "\n",
    "\n",
    "- What's **Gradient Desent**?\n",
    "\n",
    "    + A technique to use the derivative of a cost function to change the parameter values, in order to <u>minimize the cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gradient descent to minimize the cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent** is to change the parameters values so as to minimize the cost. (*which means decrease the values of $\\theta_1$ and $\\theta_2$ until reach its minimum*)\n",
    "\n",
    "First, we need to minimize the cost of function ***J***, which is a function of variable $\\theta_1$ and $\\theta_2$. Let's add a dimension for the observed cost or error ***J($\\theta_1$, $\\theta_2$)***\n",
    "\n",
    "According to this dimensions, we can represent this figure we see in this picture, <u>represents the error value for different values of parameters that is **error**, which is a function of parameters has called your **error curve** or **error bole**.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Modules_images/GD_minimize_1.png\" style='float:right; width:950px'>\n",
    "<img src=\"Modules_images/tangent_line_cost_function.png\" style='float:left; width:750px;height:547px'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, The question here is, **Which point is the best point for the cost function?** (*Very important Ref. to check [Logistic Regression Cost Error Solvers](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)*)\n",
    "\n",
    "- To minimize the positions on the error curve, you have to find the minimum value of the cost by changing the parameters. \n",
    "\n",
    "    + First we need to locate a <span style='color:orange'><b>point</b></span> on the bowl.\n",
    "\n",
    "    + you change the parameters by **($\\Delta\\theta_1$, $\\Delta\\theta_2$)** and take step on the surface.\n",
    "    \n",
    "    + As long as we're going upwards or downwards, we can go one more step. The steeper the slope, the further we can step. We can keep taking steps. As we approach the lowest point . Until we reach the flat surface.\n",
    "\n",
    "    + This's the minimum point of our curve and the **optimum ($\\theta_1$, $\\theta_2$)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What're these steps really? I mean in which direction should we take these steps to make sure we descend? And how big should the steps be?\n",
    "\n",
    "    + To find the direction and the size of these steps, in other words, to find how to update the parameters, you should calculate the gradient of the cost function at that point.\n",
    "    \n",
    "    + **Gradient** is the slope of the surface at everypoint and the direction of the gradient is the direction of the greatest uphill.\n",
    "\n",
    "        * For example; this <span style='color:orange'><b>point</b></span> if we take the partial derivative of *J*($\\theta$) with respect to each parameter at this point, it gives you the slope of the move for each parameter. Now, we've to guarantees that we go down in the <u>error curve</u> So, to decrease *J*.\n",
    "\n",
    "            <img src=\"Modules_images/derivative_J.png\" style='float: center'>\n",
    "\n",
    "    + The **Gradient value** also indicates <u> how big of a step to take</u>. \n",
    "\n",
    "        * If the slope is <u>large</u> we should take a <u>large step</u> because we're far from the minimum.\n",
    "\n",
    "           <img src=\"Modules_images/slope_steps.png\" style='float: center'>\n",
    "\n",
    "        * If the slope is <u>small</u>, we should take <u>smaller step</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The **Gradient Descent** takes increasingly smaller steps towards the minimum with each iteration. The **Partial derivative** of the cost function J is calculating using this expression. <span style='font-size:24px;color:red'>$\\frac{\\partial{J}}{\\partial\\theta_1}$</span>\n",
    "\n",
    "+ This equation returns the slope of that point and we should upgrade the parameters.\n",
    "\n",
    "+ On the opposite direction. A vector of all thses slopes is the gradient vector <span style='font-size:20px;color:red'>$\\nabla J$</span> and we can use this vector to change or update all the parameters.\n",
    "    - Take the previous values of the parameters and substract the error derivative. This results in the new parameter for <span style='font-size:20px;color:cyan'>$New_\\theta = Old_\\theta - \\nabla J$</span>\n",
    "\n",
    "\n",
    "+ The results in the new parameters for $\\theta$ that we know will <u>decrease</u> the cost. Also, multiply the **gradient value** by constant value  <span style='font-size:20px;color:yellow'>$\\eta$</span>. (estimated time of arrival)\n",
    "\n",
    "+ <span style='font-size:20px;color:yellow;font-weight:bold'>$\\eta$</span> is a **learning rate** gives us additional control on <u>how fast we move on the surface.\n",
    "\n",
    "    - **Gradient descent** is like taking steps in the current direction of the slope and the **learning rate** is like th lenght of the step you take. So, these would be our new parameters, Notice that it's an iterative operation and in each iteration we update the parameters and minimize the cost until the algorithm coverge is on **acceptable minimum**.\n",
    "\n",
    "<center>\n",
    "<img src=\"Modules_images/GD_minimize.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ This's how the **Derivative concept** goes under `Leibniz notation`. (*Ref: [Khan Academy](https://youtu.be/N2PpRnFqnqY)*)\n",
    "    - Delta $\\Delta$ or \"Change of value\", we're calling it change of the value when we need to calculate the slope into a line.\n",
    "<center>\n",
    "<img src=\"Modules_images/derivative_concept.png\" width=1250px>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training algorithm recap\n",
    "<center>\n",
    "<img src=\"Modules_images/logistic_training_recap.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (E) Evaluation Metrics in Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy\n",
    "<img src=\"Modules_images/classification_acc.png\" style='float:right'>\n",
    "\n",
    "#### How are we calculating the accuracy of classification?\n",
    "\n",
    "- We train the model, and then calculate the accuracy using test set.\n",
    "\n",
    "- We pass the test set to our model, and we find the predicted labels.\n",
    "\n",
    "- Now, the question is, \"How accurate is the model?\".\n",
    "\n",
    "- Baseically, we **compare** the <u>actual values</u> `y`  in the test set with the <u>predicted values $\\hat{y}$ </u>  by the model to calculate the accuracy of the model\n",
    "\n",
    "There're different model evaluation metrics but we just talk about three of them here;\n",
    "\n",
    "1. Jaccard index\n",
    "\n",
    "2. F1-score.\n",
    "\n",
    "3. Log Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Jaccard Index (Jaccard similarity coefficient)\n",
    "<img src=\"Modules_images/Jaccard_index.png\" style='float:right'>\n",
    "\n",
    "> Its the intersection between **actual value y** and **predicted value $\\hat{y}$**.\n",
    "\n",
    "y: Actual labels\n",
    "\n",
    "<img src=\"Modules_images/Venn_diagram.jpg\" style='float:right'>\n",
    "\n",
    "$\\hat{y}$: Predicted labels\n",
    "\n",
    "<span style='font-size:24px;'>\n",
    "$J(y,\\hat{y}) = \\frac{| y\\; \\cap\\; \\hat{y} |}{| y\\; \\cup\\; \\hat{y} |} = \\frac{| y\\; \\cap\\; \\hat{y} |}{|y| + |\\hat{y}|\\; -\\; | y\\; \\cap\\; \\hat{y} |}$\n",
    "</span>\n",
    "\n",
    "#### Example:\n",
    "\n",
    "<span style='font-size:20px;'>\n",
    "\n",
    "- y: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "- $\\hat{y}$: [1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "- $J(y,\\hat{y}) = \\frac{8}{(10+10) - 8} = 0.66$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- F1-score\n",
    "<img src=\"Modules_images/f1_score.png\" style='float:right'>\n",
    "<br><br><br>\n",
    "\n",
    "> **Confusion Matirx** is a way of seperating the labels into section which facilitate the process of check the accuracy of the predicted labels with the True label\n",
    "\n",
    "Assume, our test set has only 40 customers. This matrix shows the correct and wrong prediction $\\hat{y}$, in comparison with the actual labels `y`;\n",
    "\n",
    "- The first row, for customers whose actual churn value in the test set is **1**. You can calculate out of 40, the churn value of 15 of them is 1. \n",
    "    \n",
    "    + What have been predicted according to The **True label** is <u>6 out of 15</u>.\n",
    "    + What have been predicted wrong is <u>9 out of 15</u>.\n",
    "\n",
    "\n",
    "- The second row, for the customers whose actual churn value in the test set is **0**. You can calculate out of 40, the churn value of 25 is 0.\n",
    "    \n",
    "    + What have been predicted according to The **True label** is <u>24 out of 25</u>.\n",
    "    + What have been predicted wrong is <u>1 out of 25</u>.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Modules_images/f1_score_2.png\" style='float:right'>\n",
    "\n",
    "<span style='font-size: 18px'>\n",
    "\n",
    "1. **Precision**:  <u>Is a measure of accuracy, provided that a class label has been predicted.</u>\n",
    "\n",
    "    - Precision = TP / (TP + FP)\n",
    "\n",
    "\n",
    "2. **Recall**: <u>Is the True positive rate.</u>\n",
    "\n",
    "    - Recall = TP / (TP + FN)\n",
    "\n",
    "\n",
    "3. **F1-score**: \n",
    "<span style='font-size: 21px'>\n",
    "\n",
    "   - $2\\; \\times\\; \\frac{(\\; Precision\\; \\times\\; Recall\\; )} {(\\; Precision\\; +\\; Recall\\; )}$\n",
    "\n",
    "</span>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Log Loss (Logarithmic loss)\n",
    "<img src=\"Modules_images/Log_loss.png\" style='float:right'>\n",
    "\n",
    "> Sometimes, the output of a classifier is the probability of a class label instead of prediction of the label, itself.\n",
    "\n",
    "\n",
    "<h4> In our exmple, in Logistic Regression, the output can be the probability of customer churn. The probability value between 0 and 1.</h4>\n",
    "\n",
    "<b>The predicted output</b> is a probability value between 0 and 1. Predicting a probability of 0.13 when the <b>actual value</b> is 1, would be bad and would result in a <u>high log loss</u>\n",
    "\n",
    "\n",
    "Then, we calculate <u>the average log loss</u> across all rows of test set. Its is obvious that ideal classifiers have progressively smaller values of log loss.\n",
    "\n",
    "\n",
    "<u>Classifier with lower **log loss** has better **accuracy**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
